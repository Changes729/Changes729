# 数据挖掘基础

所谓**有指导的学习**，是指数据间存在有比较确切的关联，其目的是根据一系列变量来预测结果，结果变量指导着如何预测未来结果的学习过程。**无指导的学习**并不尝试预测输出值，而是用来探测数据中的[模式和关系？]()

数据挖掘过程：
1. 数据抽样：就是获取数据，在[统计基础](./统计基础.md)中有提到一些数据抽样的方法。
2. 数据整理：就是标准化数据。这里不是数据结构的标准化，而是需要检查数据是否有缺失，数据是否存在错误。
3. 模型构建：使用数据挖掘技术，实现数据挖掘任务。
4. 模型评价：对模型进行评估。

## 数据缺失

如果数据缺失了，一般有以下几种办法：
1. 直接删除任何缺失数据的观察（不观察了，要求有完好的数据）
2. 删除含缺失数据的变量
3. [运用估计的方法对缺失数据进行填补](./运用估计的方法对数据进行填补.md)
4. 使用可以包容含缺失值的数据挖掘算法

# 无指导学习

## 聚类分析

聚类分析的目的是将数据分组。应用场景包括*市场细分*、*用户细分*、*识别异常值*等。

聚类分析有两种方法，第一种叫`分层聚类`，第二种叫`K-均值聚类`。

**01. 相似度测量**

使用欧式距离 $d=sqrt((x1-x2)^2+(y1-y2)^2+(z1-z2)^2)$ 完成对数据的相似度测量。

对于0-1变量，可以直接使用 $匹配系数=观察值u和v项匹配的变量数目/变量总个数$ 进行计算。

_**杰卡德系数**_ $观察值u和v项非0值的变量数目/(变量总数-观察值u和v项0值匹配的变量数目)$

**02.1 分层聚类法**

在获取到数据相关度之后，将数据根据相似度进行聚合。开始时每个观察值都各自成为一类，而后依次将两个最相似的类聚合在一起。每次聚合都会减少相异聚类的相似性。

聚类相似性方法：
- 最短距离法：如果聚类里一个观察值与另一个聚类里的至少一个观察值相近，最短距离法认为这两个聚类相似。
- 最长距离法：
- 平均连接：
- 组平均连接（K重心聚类）：
- 距离差平方和法：

**02.2 K均值聚类**

分析人员需要先定义以k为基数的几个组的均值聚类办法。

**03. 关联规则**

假设陈述被称为关联规则，就是`if-else`的问题。分两步走，第一步是置信度，第二步是提升比例。

$$$
置信度 = {前提和结果}的支持度 / 前提的支持度
$$$

$$$
提升比例 = 信度 / (结果支持度 / 交易总数)
$$$

# 有指导学习
## 数据分割

将数据分三类：训练集、验证集和测试集。

## 分类准确度

$$$
总体误差率 = (n10 + n01) / (n11 + n10 + n01 + n00)
$$$

$$$
分组1的错误率 = n10 / (n11 + n10)
分组0的错误率 = n01 / (n01 + n00)
$$$

## 预测准确度

对于连续结果变量，使用平均误差或者均方根误差预测准确度。

## k最近邻算法

k最近邻算法（k-NN）既可以用于对结果进行分类，也可以用于对连续型结果进行预测。

当k-NN用作分类方法时，如果一个观察值当k个最近邻属于类别1的百分比大于某个阈值，那么这个观察值就会被分类为类别1.

当k-NN用作预测方法时，新的观察值的结果值被预测为其k个最近邻的平均值。

## 分类回归树（决策树）

**01. 决策树如何分类？**

决策树通过把实例从根结点排列到某个叶子结点来分类实例，叶子结点即为实例所属的分类。

**02. 决策树如何预测？**

回归树根据组内观察值的结果值的方差来确定该分区的非纯度，而不是像分类树那样，根据观察值属于相同种类的比例来测量分区的非纯度。最终的树被创建后，观察值的结果预测就基于新观察值所属分区的平均结果值。

## 逻辑回归（线性回归）

