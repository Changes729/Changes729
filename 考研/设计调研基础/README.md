## 总体与样本

> 关键词：抽样误差、描述统计、推论统计

描述统计：用来简化和总结数据大
推论统计：用样本的数据来推断总体情况

> 随机样本必须满足什么条件？—— 独立同分布，每一次抽取的样本服从一个总体并且互相独立。

## 变量和测量（的量表）

> 关键词：构建、构建的操作定义；称名量表、顺序量表、等距量表和等比量表（定类、定距、定量、定比）、精确值上下限

- 构建：构建是指一个不能被直接观察到的内部特质，比如智力、反应力等。
- 操作定义：我们可以把一些外部行为与构建关联起来，从而形成对构建的操作定义。

> - 房号（如100号、109号房间等）：称名量表
> - 专业（艺术、生物等）：称名量表
> - 饮料的容量（大杯、中杯等）：顺序量表
> - T恤衫大小（小、中、大）：顺序量表
> - 温度：等距量表（相对零点）
> - 间距：等距量表（相对零点）
> - 身高：等比量表（绝对零点）
>   - 可以调整后用相对身高差做等距量表
> - 年龄：等比量表（绝对零点）
> - 收入：等比量表（绝对零点）

## 频数和分布

> 关键字：频数分布、分组频数分布表、区间界限、频数分布图

## 集中趋势

> 关键词：平均值（$\mu,M$）、中数、众数、正偏态、负偏态

- 平均数
    - $Means = \sum X / n$
- 中数
    - 离散数据分奇偶、连续数据要细分

      例：有数列：1，2，3，4，4，4，4，6
      - 离散时，中数为`4 + 4/2 = 4`
      - **连续时，中数为`3.5 + 1/4 = 3.75`**

在顺序数据无法计算平均数时，可以使用中数来描述数据集中趋势。
同样的，对于称名量表无法计算平均数与中数时，只能使用众数。

**正偏态、负偏态，是指正态分布的平均值和中位数的相关性，平均值小于中位数的是负偏态（平均值负偏），平均值大于中位数的是正偏态（平均值正偏）。有个好记的方法，正态分布"尾巴"在哪里，就是哪种偏态。**（数据堆积在尾部）

> 易错题：
> 根据下面的数据：8，1，5，1，5
> a. 计算均值和标准差（注意题目没有说`总体`，所以按样本计算标准差）
> b. 将X = 8 变为 X = 18，计算新的均值和标准差（注意原队列8已经不存在了，计算标准差需要取18，最好把队列重新写出来）

### 变异性与自由度

> 关键词：全距/极差；离均差、离均差平方和（$SS$）、方差（$\sigma^2$）、标准差（$\sigma$）;样本方差（$s^2$）、样本标准差($s$);自由度（$df$）、变异系数

对于一个有$n$个分数的样本，样本变异的自由度或$df$可定义为$df = n-1$。自由度决定了样本中独立、自由变化的分数数量。

> 书中指出：因为计算离均差需要知道平均值，但是我们不知道总体的均值，所以需要计算样本均值，而计算样本均值又导致限制了样本的变异性。
>
> 这个对变异性的影响，就是其自由度变为`n-1`。
>
> 因为当样本个数`n`，平均数`M`确定后，只要知道`n-1`个量，就可以确定最后一个量的指，所以有`n-1`个量是自由变的，最后那一个量是打死变不了的。
>
> 也有数学方式证明的：

$$
S^2 = \frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{x})^2 \\

E(S^2) = E\frac{1}{n} \sum_{i=1}^{n}{(x_i- \bar{x})^2} \\
 = E\frac{1}{n}\sum_{i=1}^{n}{[(x_i-μ)-(\bar{x}-μ)]^2} \\
 = E\frac{1}{n}\sum_{i=1}^{n}{[(x_i-μ)^2-2(x_i-μ)(\bar{x}-μ)+(\bar{x}-μ)^2]} \\
 = E[\frac{1}{n}\sum_{i=1}^{n}{(x_i-μ)^2}-\frac{2(\bar{x}-μ)}{n}\sum_{i=1}^{n}{(x_i-μ)}+\frac{1}{n}\sum_{i=1}^{n}{(\bar{x}-μ)^2}] \\
 = E[\frac{1}{n}\sum_{i=1}^{n}{(x_i-μ)^2-2(\bar{x}-μ)^2+(\bar{x}-μ)^2}] \\
 = σ^2-E(\bar{x}-μ)^2 \\
 = σ^2-\frac{σ^2}{n} \\
 = \frac{n-1}{n}σ^f
$$

> 此内容显示，样本方差是总体方差的有偏估计，**它多了一个样本均值和总体均值产生的均方差。**

## 两个变量之间的关系

$$
Cov(X,Y) = E{[X-E(X)][Y-E(Y)]} \\
\rho = \frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}
$$

其他内容:
$$
Cov(X,Y) = E(XY) - E(X)E(Y)
$$

## 数据可视化

- [交叉表](https://zhuanlan.zhihu.com/p/130511948)
- [数据透视表](https://zhuanlan.zhihu.com/p/74995027)

  之所以称为数据透视表，是因为可以动态地改变它们的版面布置，以便按照不同方式分析数据，也可以重新安排行号、列标和页字段。每一次改变版面布置时，数据透视表会立即按照新的布置重新计算数据。另外，如果原始数据发生更改，则可以更新数据透视表。
- 散点图
- 直方图

  请绘制`3，1，4，3，3，4`的总体分布直方图（注意x轴从0开始、y轴有频率符号）
  (注意，直方图可能会要求标出标准差范围。)
- [箱线图](https://zhuanlan.zhihu.com/p/304545059)

## $$z$$分数

> z分数(z-score),也叫标准分数(standard score).
> $$ z = \frac{X-\mu}{σ} $$

注意$$z$$、$$X$$、$$\mu$$和$$σ$$的关系。 通过$$z$$如何计算标准差或均值，或者方差。

## 正态分布（略）
## 概率和样本均值的分布

> 关键字：样本期望（$$M$$）、样本标准差（$$σ_M = \frac{σ}{\sqrt{n}}$$）

**中心极限定理**：独立同分布的样本，其样本量n趋近于无穷大时，其样本分布接近正态分布。**当样本量达到30时，分布就已经比较接近正态分布了，此样本的正态分布服从** $$ N ~ (\mu,\frac{σ^2}{n}) $$

样本均值分布服从正态分布的两个条件：
- 样本本身服从正态分布
- 样本独立同分布且样本量大于等于30个

这里需要注意，样本标准差与总体标准差的差别。因为单个样本服从总体分布，多个样本的均值在**大数定理**下会收敛于总体均值$$\mu$$，而分布也会向均值收拢。所以，单个样本的分布服从总体，但是多个样本的集合，其服从与总体分布是有区别的，其均值会趋近于总体均值，但方差会变小。这个概率论与数理统计上也没有证明过程，只好硬记了。

## 假设检验

**假设检验的步骤**
1. 提出假设
    虚无假设（$$H_0$$）与备择假设（$$H_1$$）
2. 确定拒绝域。设立显著性水平（$$\alpha$$）
3. 搜集数据，计算样本检验统计量
4. 下结论

**根据报告的格式，用一句话来描述假设检验的结果和效应大小**：
咖啡因对于反应时间没有显著的影响。$$Z=-1.20,p>0.05,d=0.20$$
有背景音乐的教室内的学生表现更好。$$t(34) = 2.54, p < 0.05, 95%置信区间[2.509, 12.691]$$

### 测量效应

> $$Cohen's d系数$$、变异预测值（协方差平方）$$r^2$$

假设检验并没有真正评价处理效应的具体大小。

我们使用`Cohen's d系数`表示。$$d = 0.2, 0.5, 0.8$$分别对应**小、中、大处理效应**。

$$
Cohen's d系数 = \frac{样本与总体均值差异}{标准差} = \frac{\mu_M - \mu}{σ}
$$

我们知道，样本均值分布的方差会随着样本量的增大而减小$$σ_M = \frac{σ}{\sqrt{n}}$$，而`Cohen's d系数`是假设样本均值方差与总体分布相同时，其均值差偏移总体标准差的大小。可想而知，如果样本均值与总体均值差异比标准差越大，概率上就越小，越不可能出现。所以，如果`Cohen's d系数`小，就说明测量效应小。

除了`Cohen's d系数`，我们还可以用`相关系数 r`来表示两个变量的相关程度，$$r^2$$就是测量效应大小。$$r^2 = 0.01, 0.09, 0.25$$分别对应**小、中、大处理效应**。
$$
r^2 = \frac{Cov(X,Y)^2}{D(X)D(Y)} = \frac{SS_{XY}^2}{SS_XSS_Y}
$$
从[这篇文章](https://www.zhihu.com/question/437454779/answer/1663248313)看，任意二元正态分布样本都可以通过回归分析，与$$t$$分布拟合，最终得到
$$
t = \frac{r}{\sqrt{(1-r^2)/df}}
$$
从而
$$
r^2 = \frac{t^2}{t^2 + df}
$$
有意思的是，在《行为科学统计精要》p.165有提出第三种$$r^2$$的计算方式，这里先放过去了。

### 统计检验力

> 统计检验里是检验正确拒绝一个错误的虚无假设的能力。检验力是检验一个处理效应真实存在的概率。

如果当处理效应存在时，接受$$H_0$$所犯的第二类错误概率为$$p = \beta$$，那么，检验力就等于$$1 - \beta$$。

统计检验力是针对样本均值分布而言的，其主要体现在 均值分布有效应和无效应时的分布，在 $$H_0$$ 为假时正确拒绝它的概率。

与测量效应不同的是，测量效应是均值分布相对总体标准差的比值。而统计检验力则是有无效应时样本均值分布的概率。

**题目**

研究者从均值 $$\mu = 80$$，标准差$$\sigma = 20$$的正态分布的总体种选择了一个样本来检验处理研究者预期处理效应。研究者预期处理有12分的效应。使用$$\alpha = 0.05$$的双侧检验。
a. 如果样本量为n = 16, 计算检验力。（注意正反符号。0.670）
b. 如果样本量为n = 25, 计算检验力。

### $$t$$统计量

> 关键字：作为总体方差无偏估计的样本方差（$s^2$）、估计标准误（$$s_M$$）、置信区间

因为总体方差未知，所以使用样本方差作为总体方差的无偏估计进行替换。当$$t分布$$自由度大于等于45时，可以近似看作正态分布（摘自《概率论与数理统计》）。

### 两个独立样本$$t$$检验

> 关键字：合并方差（$$S_p^2$$）、两个样本的估计标准误（$$S_{(M_1-M_2)}$$）、样本标准差

根据定义，$$t=\frac{X}{\sqrt{Y/n}}$$，其中$$X$$服从标准正态分布，$$Y$$服从学生分布。我们检验两个独立样本的均值是否具有统计显著差异，需要保证：
1. 样本均值的分布属于正态分布
2. 两个样本均值分布的方差相同（方差齐性）

证明过程看[中国大学Mooc](https://www.icourse163.org/learn/ZJU-232005?tid=1465158453#/learn/content?type=detail&id=1243898687)，然后我自己总结写在了[知乎上](https://www.zhihu.com/question/392587719/answer/2230904043)。

### 两个相关样本$$t$$检验（重复测量设计）

> 关键字：重复测量设计、匹配

两个相关样本t检验的条件：
1. 每一种处理条件的观测值是独立的。
2. 差异值（D）的总体分布需要服从正态分布。因为两个相关样本t检验的样本量一般都比较小，如果差异值不服从正态分布会导致t检验有效应不足。

## 数据挖掘

> 关键字：
> 
> - 无指导学习：一类数据挖掘技术，在该类技术中算法解释在没有结果变量指导下的各种关系
> - 有指导学习：一类数据挖掘技术，在该类技术中算法学习如何预测或分区一个所研究的结果变量

### 聚类分析：

**相似度测量**：欧式距离

$$
若观察值X = (x_1, x_2, ..., x_n), Y = (y_1, y_2, ..., y_n) \\

欧式距离d = \sum_{i = 1}^{n}{x_i^2 - y_i^2}
$$

为了避免测量尺度不同而带来的变化，欧式距离的不同因素样本点都需要标准化为z分数进行计算。

$$
匹配系数 = (p(A \cap B) + p(\bar{A} \cap \bar{B})) / p(1) \\
杰卡德系数 = p(A \cap B) / p(A \cup B)
$$

**分层聚类**

1. 每个观察值各为一类。
2. 计算每个聚类的距离，将距离最短的两个类归并为一个类。记录两个类的平均距离。
  其中，计算距离可以用四种方法：
    - 最短距离法：两个类中的最短距离的两个点就是两个类的距离
    - 最长距离法：两个类中最长距离的两个点是两个类的距离
    - 平均连接：是一个类内各个点到另一个类的各个点之间的平均距离。
    - 组平均连接：是计算一个类的重心，两个类的重心就是两个类的距离
3. 循环第二步。直到最终成为一个大类。

**[K均值聚类](https://zhuanlan.zhihu.com/p/20432322)**

1. 随机取n个点，n就是最终k均值聚类的分类数。
2. 计算所有点与这n个点的距离，最近的归位一类。
3. 根据每个类，重新计算中心点
4. 重复2，3步骤，直到中心点不再变化 

**关联规则**

$$
信度 = p(B | A) / p(A) \\

提升比例 = \frac{p(B | A) / p(A)}{p(B)} 
$$

**数据分割**：三类数据集，训练集、验证集与测试集。

$$分类准确度 = p(分错的数据数)$$

样本$$Y～(y_1, y_2, ..., y_n)$$是预测结果与实际结果的偏差值集合。其预测准确度$$平均误差 = E(Y), 均方根误差= \sqrt{E(Y^2)}$$

**K最近邻算法(k-NN)**

> K-NN与K-means的区别？

> 如果一个观察值k个最近邻属于某类别的概率大于等于某个特定的阈值（如0.5）时，则该类就会被分类为类别1。或者被预测为**其k个最近邻的平均值。**

**分类回归树**

1. 通过某个变量分割数据，使数据的非纯度（基尼指数）最低
  $$Gini(D) = 1 - \sum_{k=1}^{n}{(|C_k|/|D|)^2}$$
2. 在子树中继续步骤1.
3. 修剪分类树，根据类的比例阈值（如0.5）进行修剪。

**逻辑回归**

多远线性回归以一组解释变量$$x_1,x_2,...,x_q$$，通过线性方程$$\hat{y} = b_0 + b_1x_1 + ... + b_qx_q$$预测连续因变量y。



