> 参考资料：https://mp.weixin.qq.com/s/j1sL3t6oBkKgpeo3i9X2HQ

# ChatGPT，背后的核心是什么？

> **第一个节点，早期突破：2014年，对抗生成网络（GAN）诞生，真正“教会”AI自己画画。**
>
> GAN包含两个模型，一个是生成网络G、一个是判别网络D。G负责把接收到的随机噪声生成图片，D则要判断这张图是G画的、还是现实世界就存在的。G、D互相博弈，能力也不断提升，而当D不再能判断出G生成的图片时，训练就达到了平衡。
>
> GAN的开创性在于，精巧地设计了一种“自监督学习”方式，跳出了以往监督学习需要大量标签数据的应用困境，可以广泛应用于图像生成、风格迁移、AI艺术和黑白老照片上色修复。
>
> 但其缺陷也正来源于这一开创性：由于需要同步训练两个模型，GAN的稳定性较差，容易出现模式崩溃。以及另一个有趣的现象**“海奥维提卡现象”**（the helvetica scenario）：如果G模型发现了一个能够骗过D模型的bug，它就会开始偷懒，一直用这张图片来欺骗D，导致整个平衡的无效。

> **第二个节点，大幅提升：2020年，一篇关于扩散模型（Diffusion Model）的学术论文，大幅提升AI的画画水平。**
>
> 扩散模型的原理是**“先增噪后降噪”**。首先给现有的图像逐步施加高斯噪声，直到图像被完全破坏，然后再根据给定的高斯噪声，逆向逐步还原出原图。当模型训练完成后，输入一个随机的高斯噪声，便能“无中生有”出一张图像了。
>
> 这样的设计大大降低了模型训练难度，突破了GAN模型的局限，在逼真的基础上兼具多样性，也就能够更快、更稳定的生成图片。
>
> 扩散模型在AI业界的“起飞”源于2021年1月，Open AI基于此开发出DALL·E文字生成图片模型，能够生成接近真实生活但并不真实存在的图片，让AI业界震了三震。但由于在像素空间进行了大量计算，这一模型仍存在进程缓慢、内存消耗大的缺陷。

> **第三个节点，批量生产：2022年夏天诞生的Stable Diffusion，让高大上的学术理论变得“接地气”。**
>
> 去年8月，Stability AI将扩散过程放到更低维度的潜空间（Latent Diffusion），从而开发出了Stable Diffusion模型。这个模型带来的提升，在于**资源消耗大幅降低**，消费级显卡就可以驱动的，可以操作也更为方便，普通人也可以体会到人工智能惊艳的创作能力。而且开发团队还把所有代码、模型和权重参数库都进行了开源，践行了Geek的共享精神、去中心化主义。