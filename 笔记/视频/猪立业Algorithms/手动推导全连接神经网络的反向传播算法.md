> 视频来源：https://www.bilibili.com/video/BV1ZL4y1479R/?spm_id_from=333.788&vd_source=b736aa3d7f0fdf47b59ea3021dc810ab
>
> 相关资料：
>
> - [Sigmoid 函数](https://zh.wikipedia.org/wiki/S%E5%9E%8B%E5%87%BD%E6%95%B0)：乙状函数

# 手动推导全连接神经网络的反向传播算法

根据 [Wiki](https://zh.wikipedia.org/wiki/S%E5%9E%8B%E5%87%BD%E6%95%B0)，常见的 Sigmoid 函数有逻辑斯蒂函数：$$f(x) = \frac{1}{1+e^-x}$$



有点没明白，不过大致上可以看出来，整个神经网络通过微积分的方式先算出梯度关系，从而得以在一次网络计算后，得到最终的结果进行回归。

但是很多细节其实很模糊。

- 一层单个神经元的网络模型具体是什么？
- Loss 函数究竟是什么？为什么要用这种 loss 函数？